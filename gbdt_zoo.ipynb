{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#試すモデル\n",
        "*   xgboost(GPU, CPU)\n",
        "*   lightgbm(CPU)\n",
        "*   catboost(GPU, CPU)\n",
        "*   histgradient(CPU)\n",
        "*   gradient boosting(CPU)\n",
        "*   (おまけ)TabNet(GPU, CPU)"
      ],
      "metadata": {
        "id": "rC0m6AmF-pLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#以下のコードを実行したらランタイムを再起動してください\n",
        "!pip -qqq install lightgbm -U #最新版にアップデート\n",
        "!pip -qqq install catboost\n",
        "!pip -qqq install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTwKCb0E5qL5",
        "outputId": "4d19e9ff-78b8-4461-d86e-d081fe20116e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
      ],
      "metadata": {
        "id": "DvEt9Xkm_VMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#使うデータ\n",
        "カリフォルニアの物件価格データ\n",
        "データ数: 20640\n",
        "特徴量数: 8"
      ],
      "metadata": {
        "id": "GwVjpYcn_wHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "-vvwh_uF_gRB",
        "outputId": "6dcc47af-a710-47f0-bff9-5b5143f110a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
              "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
              "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
              "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
              "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
              "...       ...       ...       ...        ...         ...       ...       ...   \n",
              "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
              "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
              "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
              "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
              "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
              "\n",
              "       Longitude  \n",
              "0        -122.23  \n",
              "1        -122.22  \n",
              "2        -122.24  \n",
              "3        -122.25  \n",
              "4        -122.25  \n",
              "...          ...  \n",
              "20635    -121.09  \n",
              "20636    -121.21  \n",
              "20637    -121.22  \n",
              "20638    -121.32  \n",
              "20639    -121.24  \n",
              "\n",
              "[20640 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-616d503d-fa2d-4aab-aebf-ad32f7cf055a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>1.5603</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.045455</td>\n",
              "      <td>1.133333</td>\n",
              "      <td>845.0</td>\n",
              "      <td>2.560606</td>\n",
              "      <td>39.48</td>\n",
              "      <td>-121.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>2.5568</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.114035</td>\n",
              "      <td>1.315789</td>\n",
              "      <td>356.0</td>\n",
              "      <td>3.122807</td>\n",
              "      <td>39.49</td>\n",
              "      <td>-121.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>1.7000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.205543</td>\n",
              "      <td>1.120092</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2.325635</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>1.8672</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.329513</td>\n",
              "      <td>1.171920</td>\n",
              "      <td>741.0</td>\n",
              "      <td>2.123209</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>2.3886</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.254717</td>\n",
              "      <td>1.162264</td>\n",
              "      <td>1387.0</td>\n",
              "      <td>2.616981</td>\n",
              "      <td>39.37</td>\n",
              "      <td>-121.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616d503d-fa2d-4aab-aebf-ad32f7cf055a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-616d503d-fa2d-4aab-aebf-ad32f7cf055a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-616d503d-fa2d-4aab-aebf-ad32f7cf055a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0        4.526\n",
              "1        3.585\n",
              "2        3.521\n",
              "3        3.413\n",
              "4        3.422\n",
              "         ...  \n",
              "20635    0.781\n",
              "20636    0.771\n",
              "20637    0.923\n",
              "20638    0.847\n",
              "20639    0.894\n",
              "Name: MedHouseVal, Length: 20640, dtype: float64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 訓練データとテストデータに8:2で分ける"
      ],
      "metadata": {
        "id": "RRnmT3li_g8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROUND = 3000 # 試行回数の設定"
      ],
      "metadata": {
        "id": "ofBJjijsXBoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Xgboost"
      ],
      "metadata": {
        "id": "r28r--XhD1iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_param = {\n",
        "    'objective': 'reg:squarederror', # 評価指標を２乗誤差に設定\n",
        "    'tree_method': 'gpu_hist' # GPUを使う設定\n",
        "}\n",
        "\n",
        "# データをXgboostフォーマットに変換\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "############### GPU ###############\n",
        "gpu_res = {} # 結果を保存する辞書\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"GPU Training\", \"=\"*10)\n",
        "model_gpu = xgb.train(xgb_param, dtrain, NUM_ROUND, evals=[(dtest, 'test')], evals_result=gpu_res, verbose_eval=300)\n",
        "print(\"GPU Training Time: %s seconds\" % (str(time.time() - tmp)))\n",
        "#予測出力\n",
        "pred = model_gpu.predict(xgb.DMatrix(X_test))\n",
        "gpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"GPU Score: {gpu_score:.5f}\")\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "xgb_param['tree_method'] = 'hist'\n",
        "cpu_res = {}\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "model_cpu = xgb.train(xgb_param, dtrain, NUM_ROUND, evals=[(dtest, 'test')], evals_result=cpu_res, verbose_eval=300)\n",
        "print(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))\n",
        "#予測出力\n",
        "pred = model_cpu.predict(xgb.DMatrix(X_test))\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-vvmfADAcj8",
        "outputId": "93f7a1c6-0c05-4178-805a-62ceb62226eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== GPU Training ==========\n",
            "[0]\ttest-rmse:1.44646\n",
            "[300]\ttest-rmse:0.456367\n",
            "[600]\ttest-rmse:0.456911\n",
            "[900]\ttest-rmse:0.457586\n",
            "[1200]\ttest-rmse:0.458219\n",
            "[1500]\ttest-rmse:0.458327\n",
            "[1800]\ttest-rmse:0.458408\n",
            "[2100]\ttest-rmse:0.458434\n",
            "[2400]\ttest-rmse:0.458434\n",
            "[2700]\ttest-rmse:0.458434\n",
            "[2999]\ttest-rmse:0.458434\n",
            "GPU Training Time: 24.135740756988525 seconds\n",
            "GPU Score: 0.21016\n",
            "========== CPU Training ==========\n",
            "[0]\ttest-rmse:1.44479\n",
            "[300]\ttest-rmse:0.457656\n",
            "[600]\ttest-rmse:0.458125\n",
            "[900]\ttest-rmse:0.458779\n",
            "[1200]\ttest-rmse:0.459078\n",
            "[1500]\ttest-rmse:0.459164\n",
            "[1800]\ttest-rmse:0.459236\n",
            "[2100]\ttest-rmse:0.459247\n",
            "[2400]\ttest-rmse:0.459247\n",
            "[2700]\ttest-rmse:0.459247\n",
            "[2999]\ttest-rmse:0.459247\n",
            "CPU Training Time: 12.712014198303223 seconds\n",
            "CPU Score: 0.21091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LightGBM\n"
      ],
      "metadata": {
        "id": "0E59kfisD4Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_param = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": \"mse\",\n",
        "    \"device_type\": \"cuda\"\n",
        "}\n",
        "\n",
        "#データをlightGBMフォーマットに変換\n",
        "dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "dtest = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "lgb_param['device_type'] = 'cpu'\n",
        "cpu_res = {}\n",
        "\n",
        "#callback関数の定義\n",
        "callbacks = [\n",
        "    lgb.log_evaluation(300),\n",
        "    lgb.record_evaluation(cpu_res)\n",
        "]\n",
        "\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "model_cpu = lgb.train(lgb_param, dtrain, NUM_ROUND, valid_sets=dtest, callbacks=callbacks)\n",
        "print(f\"CPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_cpu.predict(X_test)\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnB1WXq5E7hH",
        "outputId": "71bc41c8-db24-4e71-f357-1b3c69f2440d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== CPU Training ==========\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1837\n",
            "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 2.070980\n",
            "[300]\tvalid_0's l2: 0.192368\n",
            "[600]\tvalid_0's l2: 0.190575\n",
            "[900]\tvalid_0's l2: 0.19101\n",
            "[1200]\tvalid_0's l2: 0.191975\n",
            "[1500]\tvalid_0's l2: 0.192754\n",
            "[1800]\tvalid_0's l2: 0.19331\n",
            "[2100]\tvalid_0's l2: 0.193991\n",
            "[2400]\tvalid_0's l2: 0.194539\n",
            "[2700]\tvalid_0's l2: 0.194823\n",
            "[3000]\tvalid_0's l2: 0.195087\n",
            "CPU Training Time: 4.34246s seconds\n",
            "CPU Score: 0.19509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CatBoost"
      ],
      "metadata": {
        "id": "AeYzcWdHRMrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost as cat\n",
        "\n",
        "cat_param = {\n",
        "    \"iterations\": NUM_ROUND,\n",
        "    \"task_type\": \"GPU\",\n",
        "    \"devices\": \"0\",\n",
        "    \"verbose\": 300\n",
        "}\n",
        "\n",
        "dtrain = cat.Pool(X_train, label=y_train)\n",
        "dtest = cat.Pool(X_test, label=y_test)\n",
        "\n",
        "############### GPU ###############\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"GPU Training\", \"=\"*10)\n",
        "model_gpu = cat.CatBoostRegressor(**cat_param)\n",
        "model_gpu.fit(dtrain, eval_set=dtest)\n",
        "print(f\"GPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_gpu.predict(X_test)\n",
        "gpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"GPU Score: {gpu_score:.5f}\")\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "cat_param['task_type'] = 'CPU'\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "model_cpu = cat.CatBoostRegressor(**cat_param)\n",
        "model_cpu.fit(dtrain, eval_set=dtest)\n",
        "print(f\"CPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_cpu.predict(X_test)\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ2SQDBySqFV",
        "outputId": "e57bbbae-9ba5-4c6f-a8e5-4e7f21c20d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== GPU Training ==========\n",
            "Learning rate set to 0.061469\n",
            "0:\tlearn: 1.1131698\ttest: 1.1187512\tbest: 1.1187512 (0)\ttotal: 22.5ms\tremaining: 1m 7s\n",
            "300:\tlearn: 0.4532453\ttest: 0.4708726\tbest: 0.4708726 (300)\ttotal: 3.59s\tremaining: 32.2s\n",
            "600:\tlearn: 0.4203955\ttest: 0.4527602\tbest: 0.4527602 (600)\ttotal: 6.93s\tremaining: 27.7s\n",
            "900:\tlearn: 0.4038952\ttest: 0.4460436\tbest: 0.4459686 (897)\ttotal: 10.1s\tremaining: 23.6s\n",
            "1200:\tlearn: 0.3925180\ttest: 0.4427229\tbest: 0.4427100 (1191)\ttotal: 13.3s\tremaining: 19.9s\n",
            "1500:\tlearn: 0.3862254\ttest: 0.4412647\tbest: 0.4412643 (1498)\ttotal: 16.2s\tremaining: 16.2s\n",
            "1800:\tlearn: 0.3807451\ttest: 0.4399332\tbest: 0.4398906 (1785)\ttotal: 19.2s\tremaining: 12.8s\n",
            "2100:\tlearn: 0.3752672\ttest: 0.4385085\tbest: 0.4385085 (2100)\ttotal: 22.1s\tremaining: 9.45s\n",
            "2400:\tlearn: 0.3704167\ttest: 0.4376982\tbest: 0.4376982 (2400)\ttotal: 25s\tremaining: 6.24s\n",
            "2700:\tlearn: 0.3668240\ttest: 0.4365514\tbest: 0.4365133 (2667)\ttotal: 28s\tremaining: 3.09s\n",
            "2999:\tlearn: 0.3645759\ttest: 0.4361656\tbest: 0.4361590 (2967)\ttotal: 30.7s\tremaining: 0us\n",
            "bestTest = 0.4361589903\n",
            "bestIteration = 2967\n",
            "Shrink model to first 2968 iterations.\n",
            "GPU Training Time: 31.38163s seconds\n",
            "GPU Score: 0.19023\n",
            "========== CPU Training ==========\n",
            "Learning rate set to 0.040462\n",
            "0:\tlearn: 1.1267523\ttest: 1.1323100\tbest: 1.1323100 (0)\ttotal: 16.2ms\tremaining: 48.5s\n",
            "300:\tlearn: 0.4740223\ttest: 0.4862642\tbest: 0.4862642 (300)\ttotal: 1.56s\tremaining: 14s\n",
            "600:\tlearn: 0.4213934\ttest: 0.4577914\tbest: 0.4577914 (600)\ttotal: 2.64s\tremaining: 10.6s\n",
            "900:\tlearn: 0.3875804\ttest: 0.4438353\tbest: 0.4438353 (900)\ttotal: 3.73s\tremaining: 8.69s\n",
            "1200:\tlearn: 0.3650058\ttest: 0.4380715\tbest: 0.4380715 (1200)\ttotal: 4.8s\tremaining: 7.19s\n",
            "1500:\tlearn: 0.3470123\ttest: 0.4338606\tbest: 0.4338606 (1500)\ttotal: 5.87s\tremaining: 5.86s\n",
            "1800:\tlearn: 0.3315842\ttest: 0.4309785\tbest: 0.4309453 (1795)\ttotal: 6.96s\tremaining: 4.63s\n",
            "2100:\tlearn: 0.3179392\ttest: 0.4290986\tbest: 0.4290240 (2086)\ttotal: 8.06s\tremaining: 3.45s\n",
            "2400:\tlearn: 0.3055857\ttest: 0.4275575\tbest: 0.4275575 (2400)\ttotal: 9.18s\tremaining: 2.29s\n",
            "2700:\tlearn: 0.2951273\ttest: 0.4267492\tbest: 0.4267235 (2696)\ttotal: 10.3s\tremaining: 1.14s\n",
            "2999:\tlearn: 0.2850943\ttest: 0.4256725\tbest: 0.4256599 (2997)\ttotal: 11.9s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.4256599422\n",
            "bestIteration = 2997\n",
            "\n",
            "Shrink model to first 2998 iterations.\n",
            "CPU Training Time: 12.24066s seconds\n",
            "CPU Score: 0.18119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HistGradientBoosting"
      ],
      "metadata": {
        "id": "fr6eXWPLlyJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "\n",
        "hist_param = {\n",
        "    \"loss\": \"squared_error\",\n",
        "    \"max_iter\": NUM_ROUND,\n",
        "    \"verbose\": 300\n",
        "}\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "model_cpu = HistGradientBoostingRegressor(**hist_param)\n",
        "model_cpu.fit(X_train, y_train)\n",
        "print(f\"CPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_cpu.predict(X_test)\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmURwNUfftTc",
        "outputId": "3f014ba6-6126-4688-8e4b-3f462c53c5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== CPU Training ==========\n",
            "Binning 0.001 GB of training data: 0.098 s\n",
            "Binning 0.000 GB of validation data: 0.020 s\n",
            "Fitting gradient boosted rounds:\n",
            "[1/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58137, val loss: 0.59511, in 0.096s\n",
            "[2/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.51478, val loss: 0.52710, in 0.037s\n",
            "[3/3000] 1 tree, 31 leaves, max depth = 7, train loss: 0.45868, val loss: 0.47010, in 0.111s\n",
            "[4/3000] 1 tree, 31 leaves, max depth = 7, train loss: 0.41043, val loss: 0.42066, in 0.011s\n",
            "[5/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.36866, val loss: 0.37901, in 0.048s\n",
            "[6/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.33490, val loss: 0.34495, in 0.116s\n",
            "[7/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.30772, val loss: 0.31755, in 0.010s\n",
            "[8/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.28416, val loss: 0.29311, in 0.009s\n",
            "[9/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.26369, val loss: 0.27296, in 0.009s\n",
            "[10/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.24599, val loss: 0.25503, in 0.008s\n",
            "[11/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.23090, val loss: 0.23985, in 0.018s\n",
            "[12/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.21874, val loss: 0.22875, in 0.008s\n",
            "[13/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.20677, val loss: 0.21681, in 0.008s\n",
            "[14/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.19770, val loss: 0.20846, in 0.008s\n",
            "[15/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.18857, val loss: 0.19887, in 0.008s\n",
            "[16/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.18130, val loss: 0.19229, in 0.009s\n",
            "[17/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.17412, val loss: 0.18530, in 0.008s\n",
            "[18/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.16833, val loss: 0.17998, in 0.008s\n",
            "[19/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.16313, val loss: 0.17538, in 0.008s\n",
            "[20/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.15691, val loss: 0.16912, in 0.008s\n",
            "[21/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.15320, val loss: 0.16610, in 0.009s\n",
            "[22/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.14862, val loss: 0.16125, in 0.008s\n",
            "[23/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.14548, val loss: 0.15803, in 0.008s\n",
            "[24/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.14152, val loss: 0.15412, in 0.008s\n",
            "[25/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.13785, val loss: 0.15045, in 0.007s\n",
            "[26/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.13409, val loss: 0.14665, in 0.008s\n",
            "[27/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.13123, val loss: 0.14363, in 0.008s\n",
            "[28/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.12804, val loss: 0.14008, in 0.008s\n",
            "[29/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.12509, val loss: 0.13674, in 0.008s\n",
            "[30/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.12268, val loss: 0.13408, in 0.010s\n",
            "[31/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.12065, val loss: 0.13214, in 0.008s\n",
            "[32/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.11875, val loss: 0.13043, in 0.008s\n",
            "[33/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.11707, val loss: 0.12926, in 0.010s\n",
            "[34/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.11577, val loss: 0.12848, in 0.008s\n",
            "[35/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.11424, val loss: 0.12712, in 0.009s\n",
            "[36/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.11302, val loss: 0.12636, in 0.008s\n",
            "[37/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.11179, val loss: 0.12559, in 0.008s\n",
            "[38/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.11034, val loss: 0.12419, in 0.008s\n",
            "[39/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.10934, val loss: 0.12342, in 0.008s\n",
            "[40/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.10827, val loss: 0.12274, in 0.009s\n",
            "[41/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.10743, val loss: 0.12200, in 0.008s\n",
            "[42/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.10669, val loss: 0.12167, in 0.008s\n",
            "[43/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.10529, val loss: 0.12013, in 0.008s\n",
            "[44/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.10442, val loss: 0.11964, in 0.007s\n",
            "[45/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.10355, val loss: 0.11909, in 0.007s\n",
            "[46/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.10249, val loss: 0.11789, in 0.009s\n",
            "[47/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.10175, val loss: 0.11762, in 0.008s\n",
            "[48/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.10109, val loss: 0.11725, in 0.009s\n",
            "[49/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.10009, val loss: 0.11674, in 0.007s\n",
            "[50/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.09929, val loss: 0.11617, in 0.009s\n",
            "[51/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.09868, val loss: 0.11554, in 0.014s\n",
            "[52/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.09806, val loss: 0.11519, in 0.016s\n",
            "[53/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.09744, val loss: 0.11500, in 0.008s\n",
            "[54/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.09692, val loss: 0.11483, in 0.008s\n",
            "[55/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.09625, val loss: 0.11464, in 0.010s\n",
            "[56/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.09562, val loss: 0.11430, in 0.008s\n",
            "[57/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09494, val loss: 0.11392, in 0.008s\n",
            "[58/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09427, val loss: 0.11346, in 0.009s\n",
            "[59/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.09359, val loss: 0.11283, in 0.091s\n",
            "[60/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.09304, val loss: 0.11266, in 0.023s\n",
            "[61/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.09249, val loss: 0.11249, in 0.023s\n",
            "[62/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09183, val loss: 0.11201, in 0.423s\n",
            "[63/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.09137, val loss: 0.11186, in 0.010s\n",
            "[64/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.09089, val loss: 0.11149, in 0.008s\n",
            "[65/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.09040, val loss: 0.11119, in 0.007s\n",
            "[66/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.08987, val loss: 0.11089, in 0.007s\n",
            "[67/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.08940, val loss: 0.11083, in 0.007s\n",
            "[68/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08891, val loss: 0.11072, in 0.007s\n",
            "[69/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.08838, val loss: 0.11043, in 0.007s\n",
            "[70/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08800, val loss: 0.11048, in 0.007s\n",
            "[71/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08751, val loss: 0.10995, in 0.008s\n",
            "[72/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.08718, val loss: 0.10998, in 0.008s\n",
            "[73/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08679, val loss: 0.10992, in 0.007s\n",
            "[74/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08633, val loss: 0.10961, in 0.008s\n",
            "[75/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.08594, val loss: 0.10926, in 0.008s\n",
            "[76/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08552, val loss: 0.10906, in 0.008s\n",
            "[77/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.08512, val loss: 0.10907, in 0.010s\n",
            "[78/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.08475, val loss: 0.10896, in 0.007s\n",
            "[79/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.08436, val loss: 0.10885, in 0.007s\n",
            "[80/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.08400, val loss: 0.10872, in 0.007s\n",
            "[81/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.08363, val loss: 0.10866, in 0.007s\n",
            "[82/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08328, val loss: 0.10868, in 0.007s\n",
            "[83/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08296, val loss: 0.10860, in 0.015s\n",
            "[84/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.08254, val loss: 0.10835, in 0.008s\n",
            "[85/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08218, val loss: 0.10811, in 0.007s\n",
            "[86/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.08186, val loss: 0.10801, in 0.007s\n",
            "[87/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.08133, val loss: 0.10751, in 0.009s\n",
            "[88/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.08096, val loss: 0.10745, in 0.007s\n",
            "[89/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.08061, val loss: 0.10736, in 0.007s\n",
            "[90/3000] 1 tree, 31 leaves, max depth = 16, train loss: 0.08029, val loss: 0.10737, in 0.006s\n",
            "[91/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08002, val loss: 0.10720, in 0.006s\n",
            "[92/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07955, val loss: 0.10673, in 0.009s\n",
            "[93/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.07923, val loss: 0.10667, in 0.009s\n",
            "[94/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07885, val loss: 0.10652, in 0.008s\n",
            "[95/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07861, val loss: 0.10643, in 0.008s\n",
            "[96/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.07838, val loss: 0.10649, in 0.007s\n",
            "[97/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07804, val loss: 0.10646, in 0.006s\n",
            "[98/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07764, val loss: 0.10622, in 0.009s\n",
            "[99/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07736, val loss: 0.10610, in 0.007s\n",
            "[100/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07706, val loss: 0.10593, in 0.007s\n",
            "[101/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.07669, val loss: 0.10565, in 0.020s\n",
            "[102/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.07638, val loss: 0.10549, in 0.011s\n",
            "[103/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.07611, val loss: 0.10537, in 0.008s\n",
            "[104/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07583, val loss: 0.10520, in 0.007s\n",
            "[105/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.07548, val loss: 0.10487, in 0.007s\n",
            "[106/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.07522, val loss: 0.10476, in 0.009s\n",
            "[107/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07503, val loss: 0.10468, in 0.007s\n",
            "[108/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.07476, val loss: 0.10455, in 0.008s\n",
            "[109/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.07450, val loss: 0.10458, in 0.007s\n",
            "[110/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07425, val loss: 0.10453, in 0.008s\n",
            "[111/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.07399, val loss: 0.10438, in 0.008s\n",
            "[112/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07376, val loss: 0.10427, in 0.010s\n",
            "[113/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.07338, val loss: 0.10406, in 0.008s\n",
            "[114/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07308, val loss: 0.10424, in 0.008s\n",
            "[115/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07293, val loss: 0.10413, in 0.011s\n",
            "[116/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.07267, val loss: 0.10397, in 0.009s\n",
            "[117/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07238, val loss: 0.10406, in 0.008s\n",
            "[118/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07204, val loss: 0.10372, in 0.010s\n",
            "[119/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.07175, val loss: 0.10357, in 0.008s\n",
            "[120/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07152, val loss: 0.10354, in 0.009s\n",
            "[121/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07130, val loss: 0.10348, in 0.009s\n",
            "[122/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07109, val loss: 0.10346, in 0.007s\n",
            "[123/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07088, val loss: 0.10350, in 0.009s\n",
            "[124/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07062, val loss: 0.10343, in 0.007s\n",
            "[125/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07040, val loss: 0.10336, in 0.007s\n",
            "[126/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.07027, val loss: 0.10329, in 0.008s\n",
            "[127/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07008, val loss: 0.10317, in 0.008s\n",
            "[128/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06983, val loss: 0.10303, in 0.008s\n",
            "[129/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06960, val loss: 0.10299, in 0.007s\n",
            "[130/3000] 1 tree, 31 leaves, max depth = 17, train loss: 0.06937, val loss: 0.10293, in 0.007s\n",
            "[131/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06913, val loss: 0.10286, in 0.009s\n",
            "[132/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06889, val loss: 0.10292, in 0.008s\n",
            "[133/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06865, val loss: 0.10286, in 0.007s\n",
            "[134/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06843, val loss: 0.10269, in 0.007s\n",
            "[135/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.06816, val loss: 0.10256, in 0.007s\n",
            "[136/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06792, val loss: 0.10254, in 0.008s\n",
            "[137/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06763, val loss: 0.10261, in 0.007s\n",
            "[138/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06741, val loss: 0.10257, in 0.011s\n",
            "[139/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06728, val loss: 0.10252, in 0.006s\n",
            "[140/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06708, val loss: 0.10271, in 0.007s\n",
            "[141/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06680, val loss: 0.10279, in 0.009s\n",
            "[142/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.06657, val loss: 0.10256, in 0.008s\n",
            "[143/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06636, val loss: 0.10244, in 0.008s\n",
            "[144/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06618, val loss: 0.10237, in 0.009s\n",
            "[145/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.06601, val loss: 0.10227, in 0.007s\n",
            "[146/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06580, val loss: 0.10216, in 0.009s\n",
            "[147/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06556, val loss: 0.10190, in 0.008s\n",
            "[148/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06538, val loss: 0.10207, in 0.008s\n",
            "[149/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06516, val loss: 0.10208, in 0.007s\n",
            "[150/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06491, val loss: 0.10199, in 0.010s\n",
            "[151/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06473, val loss: 0.10199, in 0.008s\n",
            "[152/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06456, val loss: 0.10195, in 0.008s\n",
            "[153/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06439, val loss: 0.10191, in 0.007s\n",
            "[154/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06414, val loss: 0.10204, in 0.006s\n",
            "[155/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06392, val loss: 0.10181, in 0.009s\n",
            "[156/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06372, val loss: 0.10178, in 0.008s\n",
            "[157/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06359, val loss: 0.10181, in 0.007s\n",
            "[158/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06344, val loss: 0.10183, in 0.007s\n",
            "[159/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06326, val loss: 0.10177, in 0.007s\n",
            "[160/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06307, val loss: 0.10178, in 0.012s\n",
            "[161/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.06283, val loss: 0.10175, in 0.008s\n",
            "[162/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06263, val loss: 0.10181, in 0.007s\n",
            "[163/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06250, val loss: 0.10185, in 0.007s\n",
            "[164/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06236, val loss: 0.10168, in 0.008s\n",
            "[165/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06217, val loss: 0.10159, in 0.008s\n",
            "[166/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06196, val loss: 0.10151, in 0.007s\n",
            "[167/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06179, val loss: 0.10153, in 0.007s\n",
            "[168/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06161, val loss: 0.10146, in 0.008s\n",
            "[169/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06137, val loss: 0.10130, in 0.007s\n",
            "[170/3000] 1 tree, 31 leaves, max depth = 19, train loss: 0.06116, val loss: 0.10129, in 0.007s\n",
            "[171/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06097, val loss: 0.10141, in 0.012s\n",
            "[172/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06087, val loss: 0.10136, in 0.008s\n",
            "[173/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.06067, val loss: 0.10136, in 0.007s\n",
            "[174/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06051, val loss: 0.10143, in 0.008s\n",
            "[175/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.06031, val loss: 0.10123, in 0.008s\n",
            "[176/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06016, val loss: 0.10113, in 0.007s\n",
            "[177/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.06001, val loss: 0.10105, in 0.007s\n",
            "[178/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05978, val loss: 0.10098, in 0.021s\n",
            "[179/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05967, val loss: 0.10097, in 0.008s\n",
            "[180/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05952, val loss: 0.10089, in 0.007s\n",
            "[181/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05937, val loss: 0.10086, in 0.007s\n",
            "[182/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05918, val loss: 0.10100, in 0.007s\n",
            "[183/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05901, val loss: 0.10088, in 0.007s\n",
            "[184/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05890, val loss: 0.10089, in 0.006s\n",
            "[185/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05873, val loss: 0.10073, in 0.010s\n",
            "[186/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.05852, val loss: 0.10073, in 0.007s\n",
            "[187/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05840, val loss: 0.10073, in 0.008s\n",
            "[188/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05825, val loss: 0.10071, in 0.008s\n",
            "[189/3000] 1 tree, 31 leaves, max depth = 16, train loss: 0.05806, val loss: 0.10058, in 0.008s\n",
            "[190/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05792, val loss: 0.10058, in 0.007s\n",
            "[191/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05775, val loss: 0.10057, in 0.007s\n",
            "[192/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05759, val loss: 0.10050, in 0.007s\n",
            "[193/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05742, val loss: 0.10048, in 0.007s\n",
            "[194/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05725, val loss: 0.10040, in 0.008s\n",
            "[195/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05709, val loss: 0.10030, in 0.007s\n",
            "[196/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05692, val loss: 0.10007, in 0.008s\n",
            "[197/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05679, val loss: 0.10011, in 0.008s\n",
            "[198/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05668, val loss: 0.10011, in 0.007s\n",
            "[199/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05655, val loss: 0.10009, in 0.008s\n",
            "[200/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05641, val loss: 0.10000, in 0.007s\n",
            "[201/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05625, val loss: 0.10003, in 0.007s\n",
            "[202/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05608, val loss: 0.09986, in 0.007s\n",
            "[203/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05583, val loss: 0.09972, in 0.007s\n",
            "[204/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05571, val loss: 0.09965, in 0.008s\n",
            "[205/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.05560, val loss: 0.09965, in 0.007s\n",
            "[206/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05546, val loss: 0.09970, in 0.007s\n",
            "[207/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05532, val loss: 0.09967, in 0.008s\n",
            "[208/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05519, val loss: 0.09960, in 0.006s\n",
            "[209/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05507, val loss: 0.09955, in 0.018s\n",
            "[210/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05492, val loss: 0.09952, in 0.007s\n",
            "[211/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05478, val loss: 0.09950, in 0.007s\n",
            "[212/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05468, val loss: 0.09946, in 0.014s\n",
            "[213/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05455, val loss: 0.09944, in 0.009s\n",
            "[214/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05437, val loss: 0.09925, in 0.008s\n",
            "[215/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.05421, val loss: 0.09914, in 0.012s\n",
            "[216/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05409, val loss: 0.09917, in 0.007s\n",
            "[217/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05393, val loss: 0.09917, in 0.007s\n",
            "[218/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05384, val loss: 0.09920, in 0.007s\n",
            "[219/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05370, val loss: 0.09928, in 0.007s\n",
            "[220/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05359, val loss: 0.09926, in 0.010s\n",
            "[221/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05348, val loss: 0.09926, in 0.008s\n",
            "[222/3000] 1 tree, 31 leaves, max depth = 16, train loss: 0.05332, val loss: 0.09917, in 0.007s\n",
            "[223/3000] 1 tree, 31 leaves, max depth = 16, train loss: 0.05320, val loss: 0.09910, in 0.007s\n",
            "[224/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05305, val loss: 0.09913, in 0.007s\n",
            "[225/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.05297, val loss: 0.09917, in 0.014s\n",
            "[226/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05276, val loss: 0.09899, in 0.007s\n",
            "[227/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05264, val loss: 0.09895, in 0.006s\n",
            "[228/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05252, val loss: 0.09897, in 0.008s\n",
            "[229/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.05240, val loss: 0.09888, in 0.007s\n",
            "[230/3000] 1 tree, 31 leaves, max depth = 15, train loss: 0.05228, val loss: 0.09892, in 0.008s\n",
            "[231/3000] 1 tree, 31 leaves, max depth = 9, train loss: 0.05216, val loss: 0.09892, in 0.007s\n",
            "[232/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05205, val loss: 0.09891, in 0.008s\n",
            "[233/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05192, val loss: 0.09893, in 0.007s\n",
            "[234/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.05180, val loss: 0.09886, in 0.007s\n",
            "[235/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05165, val loss: 0.09868, in 0.007s\n",
            "[236/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05153, val loss: 0.09873, in 0.009s\n",
            "[237/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05142, val loss: 0.09875, in 0.007s\n",
            "[238/3000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05129, val loss: 0.09883, in 0.007s\n",
            "[239/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05122, val loss: 0.09886, in 0.006s\n",
            "[240/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05110, val loss: 0.09882, in 0.007s\n",
            "[241/3000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05095, val loss: 0.09880, in 0.009s\n",
            "[242/3000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05084, val loss: 0.09880, in 0.007s\n",
            "[243/3000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05075, val loss: 0.09882, in 0.007s\n",
            "[244/3000] 1 tree, 31 leaves, max depth = 8, train loss: 0.05063, val loss: 0.09884, in 0.006s\n",
            "[245/3000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05044, val loss: 0.09884, in 0.009s\n",
            "Fit 245 trees in 3.367 s, (7595 total leaves)\n",
            "Time spent computing histograms: 0.438s\n",
            "Time spent finding best splits:  0.293s\n",
            "Time spent applying splits:      0.346s\n",
            "Time spent predicting:           0.015s\n",
            "CPU Training Time: 3.37328s seconds\n",
            "CPU Score: 0.19702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GradientBoosting"
      ],
      "metadata": {
        "id": "M-gqsxil5LSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "hist_param = {\n",
        "    \"loss\": \"squared_error\",\n",
        "    \"n_estimators\": 50,\n",
        "    \"verbose\": 300\n",
        "}\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "model_cpu = GradientBoostingRegressor(**hist_param)\n",
        "model_cpu.fit(X_train, y_train)\n",
        "print(f\"CPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_cpu.predict(X_test)\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPwfZlJlm_C0",
        "outputId": "c1b893c3-022c-4733-9863-16dbbe4f2239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== CPU Training ==========\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1940            1.80s\n",
            "         2           1.0837            1.75s\n",
            "         3           0.9928            1.69s\n",
            "         4           0.9123            1.76s\n",
            "         5           0.8460            1.70s\n",
            "         6           0.7931            1.65s\n",
            "         7           0.7442            1.60s\n",
            "         8           0.7038            1.56s\n",
            "         9           0.6699            1.52s\n",
            "        10           0.6412            1.48s\n",
            "        11           0.6143            1.44s\n",
            "        12           0.5906            1.40s\n",
            "        13           0.5703            1.36s\n",
            "        14           0.5533            1.32s\n",
            "        15           0.5325            1.29s\n",
            "        16           0.5188            1.25s\n",
            "        17           0.5063            1.22s\n",
            "        18           0.4946            1.19s\n",
            "        19           0.4831            1.16s\n",
            "        20           0.4709            1.12s\n",
            "        21           0.4621            1.08s\n",
            "        22           0.4424            1.04s\n",
            "        23           0.4343            1.00s\n",
            "        24           0.4272            0.97s\n",
            "        25           0.4157            0.93s\n",
            "        26           0.4096            0.89s\n",
            "        27           0.3980            0.86s\n",
            "        28           0.3878            0.82s\n",
            "        29           0.3824            0.79s\n",
            "        30           0.3781            0.75s\n",
            "        31           0.3702            0.71s\n",
            "        32           0.3657            0.68s\n",
            "        33           0.3621            0.64s\n",
            "        34           0.3581            0.60s\n",
            "        35           0.3534            0.56s\n",
            "        36           0.3464            0.53s\n",
            "        37           0.3436            0.49s\n",
            "        38           0.3383            0.45s\n",
            "        39           0.3340            0.41s\n",
            "        40           0.3317            0.37s\n",
            "        41           0.3296            0.34s\n",
            "        42           0.3281            0.30s\n",
            "        43           0.3257            0.26s\n",
            "        44           0.3231            0.22s\n",
            "        45           0.3217            0.19s\n",
            "        46           0.3201            0.15s\n",
            "        47           0.3188            0.11s\n",
            "        48           0.3168            0.07s\n",
            "        49           0.3139            0.04s\n",
            "        50           0.3108            0.00s\n",
            "CPU Training Time: 1.87238s seconds\n",
            "CPU Score: 0.31861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(おまけ)TabNet"
      ],
      "metadata": {
        "id": "1xNqIs7wqop-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "tab_param = {\n",
        "    \"device_name\": \"cuda\",\n",
        "    \"verbose\": 3,\n",
        "}\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "############### GPU ###############\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"GPU Training\", \"=\"*10)\n",
        "model_gpu = TabNetRegressor(**tab_param)\n",
        "model_gpu.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=[\"mse\"], max_epochs=NUM_ROUND)\n",
        "print(f\"GPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_gpu.predict(X_test)\n",
        "gpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"GPU Score: {gpu_score:.5f}\")\n",
        "\n",
        "############### CPU ###############\n",
        "tmp = time.time()\n",
        "# 訓練開始\n",
        "print(\"=\"*10, \"CPU Training\", \"=\"*10)\n",
        "tab_param[\"device_name\"] = \"cpu\"\n",
        "model_cpu = TabNetRegressor(**tab_param)\n",
        "model_cpu.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=[\"mse\"], max_epochs=NUM_ROUND)\n",
        "print(f\"CPU Training Time: {(time.time() - tmp):.5f}s seconds\")\n",
        "#予測出力\n",
        "pred = model_cpu.predict(X_test)\n",
        "cpu_score = mean_squared_error(y_test, pred)\n",
        "print(f\"CPU Score: {cpu_score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSfpQBRlqXNj",
        "outputId": "103d0077-34cb-4b0f-fba3-8df5496eed9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== GPU Training ==========\n",
            "Device used : cuda\n",
            "epoch 0  | loss: 2.98552 | val_0_mse: 547.89931|  0:00:03s\n",
            "epoch 3  | loss: 0.55137 | val_0_mse: 2.59755 |  0:00:05s\n",
            "epoch 6  | loss: 0.45334 | val_0_mse: 114.42751|  0:00:07s\n",
            "epoch 9  | loss: 0.41024 | val_0_mse: 134.79747|  0:00:09s\n",
            "epoch 12 | loss: 0.38569 | val_0_mse: 264.38136|  0:00:11s\n",
            "\n",
            "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 2.21771\n",
            "Best weights from best epoch are automatically used!\n",
            "GPU Training Time: 17.10545s seconds\n",
            "GPU Score: 2.21771\n",
            "========== CPU Training ==========\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 2.96753 | val_0_mse: 1237.73933|  0:00:00s\n",
            "epoch 3  | loss: 0.46278 | val_0_mse: 28.89551|  0:00:02s\n",
            "epoch 6  | loss: 0.40232 | val_0_mse: 70.95249|  0:00:03s\n",
            "epoch 9  | loss: 0.37545 | val_0_mse: 9.08829 |  0:00:05s\n",
            "epoch 12 | loss: 0.37093 | val_0_mse: 93.13641|  0:00:06s\n",
            "epoch 15 | loss: 0.36743 | val_0_mse: 15.99123|  0:00:08s\n",
            "epoch 18 | loss: 0.35166 | val_0_mse: 6.70646 |  0:00:10s\n",
            "\n",
            "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 2.93858\n",
            "Best weights from best epoch are automatically used!\n",
            "CPU Training Time: 10.36927s seconds\n",
            "CPU Score: 2.93858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1QRkQIotAvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}